{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "387c2f03",
   "metadata": {},
   "source": [
    "1. What is a Decision Tree, and how does it work in the context of classification?\n",
    "    - A Decision Tree is a supervised learning algorithm that splits data into branches based on feature values to predict a target class.\n",
    "It works like a flowchart—each internal node represents a condition on a feature, each branch a decision outcome, and each leaf a class label.\n",
    "The model learns rules to classify unseen data by minimizing impurity at each split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216f464",
   "metadata": {},
   "source": [
    "2.  Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
    "    - Gini Impurity: Measures how often a randomly chosen element is misclassified.\n",
    "\n",
    "        Entropy: Measures information disorder.\n",
    "\n",
    "        Lower impurity = better split; trees choose splits that minimize impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e10abd",
   "metadata": {},
   "source": [
    "3. What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
    "    - Pre-pruning: Stops tree growth early using parameters like max_depth. Prevents overfitting and saves computation time.\n",
    "\n",
    "        Post-pruning: Grows full tree first, then prunes less useful branches. Improves generalization and accuracy on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359fc4e",
   "metadata": {},
   "source": [
    "4. What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
    "    - Information Gain = Reduction in impurity after a split.\n",
    "\n",
    "        It measures how much “information” a feature provides about the target.\n",
    "        \n",
    "        Higher gain = better split, so the tree uses it to choose the best dividing feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc52cc",
   "metadata": {},
   "source": [
    "5. What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
    "    - Applications: Loan approval, disease diagnosis, churn prediction, fraud detection.\n",
    "\n",
    "        Advantages: Easy to interpret, handles both numerical and categorical data.\n",
    "    \n",
    "        Limitations: Prone to overfitting, unstable with small data changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b1091",
   "metadata": {},
   "source": [
    "6. Write a Python program to:\n",
    "● Load the Iris Dataset\n",
    "\n",
    "● Train a Decision Tree Classifier using the Gini criterion\n",
    "\n",
    "● Print the model’s accuracy and feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ba9fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Feature Importances: [0.         0.01667014 0.90614339 0.07718647]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Feature Importances:\", model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7b45f",
   "metadata": {},
   "source": [
    "7. Write a Python program to:\n",
    "\n",
    "● Load the Iris Dataset\n",
    "\n",
    "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
    "\n",
    "a fully-grown tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890503e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Accuracy: 1.0\n",
      "Depth=3 Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "full_tree = DecisionTreeClassifier(random_state=42)\n",
    "limited_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "full_tree.fit(X_train, y_train)\n",
    "limited_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Full Tree Accuracy:\", accuracy_score(y_test, full_tree.predict(X_test)))\n",
    "print(\"Depth=3 Accuracy:\", accuracy_score(y_test, limited_tree.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61396fb",
   "metadata": {},
   "source": [
    "8. Write a Python program to:\n",
    "\n",
    "● Load the California Housing dataset from sklearn\n",
    "\n",
    "● Train a Decision Tree Regressor\n",
    "\n",
    "● Print the Mean Squared Error (MSE) and feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ffdb18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.495235205629094\n",
      "Feature Importances: [0.52850909 0.05188354 0.05297497 0.02866046 0.03051568 0.13083768\n",
      " 0.09371656 0.08290203]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "reg = DecisionTreeRegressor(random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Feature Importances:\", reg.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f062f4",
   "metadata": {},
   "source": [
    "9. Write a Python program to:\n",
    "\n",
    "● Load the Iris Dataset\n",
    "\n",
    "● Tune the Decision Tree’s max_depth and min_samples_split using GridSearchCV\n",
    "\n",
    "● Print the best parameters and the resulting model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17ca7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Best Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {'max_depth': [2, 3, 4, 5], 'min_samples_split': [2, 3, 4]}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=42), params, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_test, grid.best_estimator_.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd0d41",
   "metadata": {},
   "source": [
    "10. Imagine you’re working as a data scientist for a healthcare company that\n",
    "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
    "mixed data types and some missing values.\n",
    "Explain the step-by-step process you would follow to:\n",
    "● Handle the missing values\n",
    "● Encode the categorical features\n",
    "● Train a Decision Tree model\n",
    "● Tune its hyperparameters\n",
    "● Evaluate its performance\n",
    "And describe what business value this model could provide in the real-world\n",
    "setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a8a6e",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "Handle Missing Values: Use SimpleImputer to fill missing numeric data (mean/median) and categorical data (most frequent).\n",
    "\n",
    "Encode Categoricals: Use LabelEncoder or OneHotEncoder.\n",
    "\n",
    "Train Model: Fit a DecisionTreeClassifier.\n",
    "\n",
    "Tune Hyperparameters: Apply GridSearchCV to optimize depth, split size, etc.\n",
    "\n",
    "Evaluate: Use accuracy_score or roc_auc_score.\n",
    "\n",
    "Business Value: Helps doctors predict diseases early, improving treatment and saving costs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
